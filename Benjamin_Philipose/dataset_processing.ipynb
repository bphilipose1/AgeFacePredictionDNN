{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import preprocess_and_save_image\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\\\UTKFaceAugmented.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataframe to Input and Target Features \n",
    "## Chose to be a Regression Task (Target = age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'filename', 'age', 'gender', 'race', 'age_range',\n",
      "       'num_haircuts_life', 'has_tiktok', 'remembers_disco', 'uses_skincare',\n",
      "       'max_annual_earnings'],\n",
      "      dtype='object')\n",
      "   Unnamed: 0                                filename  age  gender   race  \\\n",
      "0           0  100_0_0_20170112213500903.jpg.chip.jpg  100    male  white   \n",
      "1           1  100_0_0_20170112215240346.jpg.chip.jpg  100    male  white   \n",
      "2           2  100_1_0_20170110183726390.jpg.chip.jpg  100  female  white   \n",
      "3           3  100_1_0_20170112213001988.jpg.chip.jpg  100  female  white   \n",
      "4           4  100_1_0_20170112213303693.jpg.chip.jpg  100  female  white   \n",
      "\n",
      "  age_range  num_haircuts_life has_tiktok remembers_disco uses_skincare  \\\n",
      "0   100-119                360         no              no            no   \n",
      "1   100-119                627         no              no            no   \n",
      "2   100-119                687         no             yes            no   \n",
      "3   100-119                710         no              no            no   \n",
      "4   100-119                614         no              no            no   \n",
      "\n",
      "   max_annual_earnings  \n",
      "0         32890.160162  \n",
      "1         29870.803247  \n",
      "2         62930.622654  \n",
      "3         31105.957009  \n",
      "4         63977.673549  \n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.head())\n",
    "target = df['age']\n",
    "features = df.drop(['age', 'age_range'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Model 1 - Linear Regression Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender   race  num_haircuts_life has_tiktok remembers_disco uses_skincare  \\\n",
      "0    male  white                360         no              no            no   \n",
      "1    male  white                627         no              no            no   \n",
      "2  female  white                687         no             yes            no   \n",
      "3  female  white                710         no              no            no   \n",
      "4  female  white                614         no              no            no   \n",
      "\n",
      "   max_annual_earnings  \n",
      "0         32890.160162  \n",
      "1         29870.803247  \n",
      "2         62930.622654  \n",
      "3         31105.957009  \n",
      "4         63977.673549  \n"
     ]
    }
   ],
   "source": [
    "#Selecting potentially relevant features\n",
    "cm_features = ['gender', 'race', 'num_haircuts_life', 'has_tiktok', 'remembers_disco', 'uses_skincare', 'max_annual_earnings']\n",
    "cm_df = df[cm_features]\n",
    "\n",
    "print(cm_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features\n",
      "gender\n",
      "['male' 'female']\n",
      "race\n",
      "['white' 'asian' 'black' 'indian' 'other']\n",
      "has_tiktok\n",
      "['no' 'yes']\n",
      "remembers_disco\n",
      "['no' 'yes']\n",
      "uses_skincare\n",
      "['no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['gender', 'race', 'has_tiktok', 'remembers_disco', 'uses_skincare']\n",
    "\n",
    "print('Categorical Features')\n",
    "for feature in categorical_features:\n",
    "    print(feature)\n",
    "    print(cm_df[feature].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert 2-state classification columns to binary ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df.loc[:, 'has_tiktok'] = cm_df['has_tiktok'].map({'no': 0, 'yes': 1})\n",
    "cm_df.loc[:, 'remembers_disco'] = cm_df['remembers_disco'].map({'no': 0, 'yes': 1})\n",
    "cm_df.loc[:, 'uses_skincare'] = cm_df['uses_skincare'].map({'no': 0, 'yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the rest of the multi-state categorical columns to one hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "multi_categorical_columns = ['race', 'gender']\n",
    "cm_df = pd.get_dummies(cm_df, columns=multi_categorical_columns)\n",
    "#To maintain snake_case naming convention\n",
    "cm_df.columns = cm_df.columns.str.replace('-', '_')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensure all feature datatypes are integers now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe after conversion preprocessing and one hot encoding\n",
      "num_haircuts_life        int64\n",
      "has_tiktok               int32\n",
      "remembers_disco          int32\n",
      "uses_skincare            int32\n",
      "max_annual_earnings    float64\n",
      "race_asian               int32\n",
      "race_black               int32\n",
      "race_indian              int32\n",
      "race_other               int32\n",
      "race_white               int32\n",
      "gender_female            int32\n",
      "gender_male              int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for features in cm_df.columns:\n",
    "    if (cm_df[features].dtype == bool) or (cm_df[features].dtype == object):\n",
    "        cm_df[features] = cm_df[features].astype(int)\n",
    "\n",
    "print('\\nDataframe after conversion preprocessing and one hot encoding')\n",
    "print(cm_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for missing values in the dataset, incase NaN needs to be dropped or interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_haircuts_life      0\n",
      "has_tiktok             0\n",
      "remembers_disco        0\n",
      "uses_skincare          0\n",
      "max_annual_earnings    0\n",
      "race_asian             0\n",
      "race_black             0\n",
      "race_indian            0\n",
      "race_other             0\n",
      "race_white             0\n",
      "gender_female          0\n",
      "gender_male            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(cm_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Bias Column (Y-intercept) for Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df['bias'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Linear Regression Data into Train, Validation, Test Set data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont stratify because its a regression problem\n",
    "cm_x_train, cm_x_check, cm_y_train, cm_y_check = train_test_split(cm_df, target, test_size=0.2, random_state=42)\n",
    "cm_x_val, cm_x_test, cm_y_val, cm_y_test = train_test_split(cm_x_check, cm_y_check, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Standardization to Continuous Numerical Data (No single feature dominates the learning process due to having a larger scale than others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       num_haircuts_life  has_tiktok  remembers_disco  uses_skincare  \\\n",
      "5096           -0.298800           0                0              0   \n",
      "19586           1.915160           0                0              1   \n",
      "9835           -0.055341           1                0              0   \n",
      "13631          -0.245544           1                0              1   \n",
      "9807           -0.390098           0                0              1   \n",
      "\n",
      "       max_annual_earnings  race_asian  race_black  race_indian  race_other  \\\n",
      "5096             -0.171502           0           0            0           0   \n",
      "19586            -0.257435           0           0            1           0   \n",
      "9835             -0.012558           0           0            0           0   \n",
      "13631             0.075031           0           0            1           0   \n",
      "9807             -0.089092           0           0            0           0   \n",
      "\n",
      "       race_white  gender_female  gender_male  bias  \n",
      "5096            1              0            1     1  \n",
      "19586           0              0            1     1  \n",
      "9835            1              1            0     1  \n",
      "13631           0              1            0     1  \n",
      "9807            1              1            0     1  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['num_haircuts_life', 'max_annual_earnings']\n",
    "cm_x_train[columns_to_scale] = scaler.fit_transform(cm_x_train[columns_to_scale])\n",
    "cm_x_val[columns_to_scale] = scaler.transform(cm_x_val[columns_to_scale])\n",
    "cm_x_test[columns_to_scale] = scaler.transform(cm_x_test[columns_to_scale])\n",
    "\n",
    "print(cm_x_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Train, Val, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the data for use in the regression model\n",
    "cm_x_train = cm_x_train.to_numpy()\n",
    "cm_x_test = cm_x_test.to_numpy()\n",
    "cm_y_train = cm_y_train.to_numpy()\n",
    "cm_y_test = cm_y_test.to_numpy()\n",
    "cm_x_val = cm_x_val.to_numpy()\n",
    "cm_y_val = cm_y_val.to_numpy()\n",
    "\n",
    "directory = 'tensor_collection'\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "torch.save(cm_x_train, directory + '/cm_x_train.pt')\n",
    "torch.save(cm_x_test, directory + '/cm_x_test.pt')\n",
    "torch.save(cm_y_train, directory + '/cm_y_train.pt')\n",
    "torch.save(cm_y_test, directory + '/cm_y_test.pt')\n",
    "torch.save(cm_x_val, directory + '/cm_x_val.pt')\n",
    "torch.save(cm_y_val, directory + '/cm_y_val.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Model 2 - Convolutional Neural Network\n",
    "### AND\n",
    "# Data Preprocessing for Model 3 - Multi Modela Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_haircuts_life  has_tiktok  remembers_disco  uses_skincare  \\\n",
      "0                360           0                0              0   \n",
      "1                627           0                0              0   \n",
      "2                687           0                1              0   \n",
      "3                710           0                0              0   \n",
      "4                614           0                0              0   \n",
      "\n",
      "   max_annual_earnings  race_asian  race_black  race_indian  race_other  \\\n",
      "0         32890.160162           0           0            0           0   \n",
      "1         29870.803247           0           0            0           0   \n",
      "2         62930.622654           0           0            0           0   \n",
      "3         31105.957009           0           0            0           0   \n",
      "4         63977.673549           0           0            0           0   \n",
      "\n",
      "   race_white  gender_female  gender_male  \n",
      "0           1              0            1  \n",
      "1           1              0            1  \n",
      "2           1              1            0  \n",
      "3           1              1            0  \n",
      "4           1              1            0  \n"
     ]
    }
   ],
   "source": [
    "nn_df = cm_df\n",
    "nn_df.drop(['bias'], axis=1, inplace=True)\n",
    "print(nn_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_haircuts_life  has_tiktok  remembers_disco  uses_skincare  \\\n",
      "0                360           0                0              0   \n",
      "1                627           0                0              0   \n",
      "2                687           0                1              0   \n",
      "3                710           0                0              0   \n",
      "4                614           0                0              0   \n",
      "\n",
      "   max_annual_earnings  race_asian  race_black  race_indian  race_other  \\\n",
      "0         32890.160162           0           0            0           0   \n",
      "1         29870.803247           0           0            0           0   \n",
      "2         62930.622654           0           0            0           0   \n",
      "3         31105.957009           0           0            0           0   \n",
      "4         63977.673549           0           0            0           0   \n",
      "\n",
      "   race_white  gender_female  gender_male  \\\n",
      "0           1              0            1   \n",
      "1           1              0            1   \n",
      "2           1              1            0   \n",
      "3           1              1            0   \n",
      "4           1              1            0   \n",
      "\n",
      "                                            filename  \n",
      "0  preprocessed_images\\100_0_0_20170112213500903....  \n",
      "1  preprocessed_images\\100_0_0_20170112215240346....  \n",
      "2  preprocessed_images\\100_1_0_20170110183726390....  \n",
      "3  preprocessed_images\\100_1_0_20170112213001988....  \n",
      "4  preprocessed_images\\100_1_0_20170112213303693....  \n"
     ]
    }
   ],
   "source": [
    "# Create directory to store images\n",
    "in_directory = 'data\\\\images'\n",
    "out_directory = 'preprocessed_images'\n",
    "os.makedirs(out_directory, exist_ok=True)\n",
    "\n",
    "nn_df['filename'] = df['filename'].astype(str)\n",
    "nn_df.apply(lambda row: preprocess_and_save_image(in_directory + '\\\\' + row['filename'], out_directory + '\\\\' + row['filename']), axis=1)\n",
    "\n",
    "nn_df['filename'] = out_directory + '\\\\' + nn_df['filename'].astype(str)\n",
    "\n",
    "\n",
    "print(nn_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide data into train, val, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_x_train, nn_x_check, nn_age_train, nn_age_check = train_test_split(nn_df, target, test_size=0.2, random_state=42)\n",
    "nn_x_val, nn_x_test, nn_age_val, nn_age_test = train_test_split(nn_x_check, nn_age_check, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the Train, Val, Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the traiin test validation as csv as it stores filename (String)\n",
    "nn_x_train.to_csv(directory + '/nn_x_train.csv', index=False)\n",
    "nn_x_test.to_csv(directory + '/nn_x_test.csv', index=False)\n",
    "nn_x_val.to_csv(directory + '/nn_x_val.csv', index=False)\n",
    "\n",
    "#convert all age to torch tensors as its only numerical\n",
    "nn_age_train = nn_age_train.to_numpy()\n",
    "nn_age_test = nn_age_test.to_numpy()\n",
    "nn_age_val = nn_age_val.to_numpy()\n",
    "\n",
    "torch.save(nn_age_train, directory + '/nn_y_train.pt')\n",
    "torch.save(nn_age_test, directory + '/nn_y_test.pt')\n",
    "torch.save(nn_age_val, directory + '/nn_y_val.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
